{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Machine Learning with Azure Machine Learning Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start Overview\n",
    "\n",
    "In this quickstart we will be building a regression model to predict **Taxi Fares in New York City**. We will download a preprocessed labeled training data with features such as number of passengers, trip distance, datetime, holiday information and weather information.\n",
    "\n",
    "You will use compute resources provided by Azure Machine Learning (AML) to **remotely** train a **set** of models using **Automated Machine Learning**, evaluate performance of each model and pick the best performing model to deploy as a web service hosted by **Azure Container Instance**.\n",
    "\n",
    "Because you will be using the Azure Machine Learning SDK, you will be able to provision all your required Azure resources directly from this notebook, without having to use the Azure Portal to create any resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "To begin, you will need to provide the following information about your Azure Subscription.\n",
    "\n",
    "**If you are using your own Azure subscription, please provide names for subscription_id, resource_group, workspace_name and workspace_region to use.** Note that the workspace needs to be of type [Machine Learning Workspace](https://docs.microsoft.com/en-us/azure/machine-learning/service/setup-create-workspace).\n",
    "\n",
    "**If an environment is provided to you be sure to replace XXXXX in the values below with your unique identifier.**\n",
    "\n",
    "In the following cell, be sure to set the values for `subscription_id`, `resource_group`, `workspace_name` and `workspace_region` as directed by the comments (*these values can be acquired from the Azure Portal*).\n",
    "\n",
    "To get these values, do the following:\n",
    "1. Navigate to the Azure Portal and login with the credentials provided.\n",
    "2. From the left hand menu, under Favorites, select `Resource Groups`.\n",
    "3. In the list, select the resource group with the name similar to `XXXXX`.\n",
    "4. From the Overview tab, capture the desired values.\n",
    "\n",
    "Execute the following cell by selecting the `>|Run` button in the command bar above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide the Subscription ID of your existing Azure subscription\n",
    "subscription_id = \"\" # <- needs to be the subscription with the Quick-Starts resource group\n",
    "\n",
    "#Provide values for the existing Resource Group \n",
    "resource_group = \"Quick-Starts-XXXXX\" # <- replace XXXXX with your unique identifier\n",
    "\n",
    "#Provide the Workspace Name and Azure Region of the Azure Machine Learning Workspace\n",
    "workspace_name = \"quick-starts-ws-XXXXX\" # <- replace XXXXX with your unique identifier\n",
    "workspace_region = \"eastus\" # <- region of your Quick-Starts resource group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants, you can leave these values as they are or experiment with changing them after you have completed the notebook once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'automl-regression'\n",
    "project_folder = './automl-regression'\n",
    "\n",
    "# this is the URL to the CSV file containing the training and test data\n",
    "data_url = ('https://mlopswsstorage9733ce347d.blob.core.windows.net/'\n",
    "            'azureml-blobstore-4a000316-c93b-407f-b246-ed8471c34db8/'\n",
    "            'nyc-taxi-sample-data/nyc-taxi-sample-data.csv')\n",
    "\n",
    "cluster_name = \"cpucluster\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Azure Machine Learning SDK provides a comprehensive set of a capabilities that you can use directly within a notebook including:\n",
    "- Creating a **Workspace** that acts as the root object to organize all artifacts and resources used by Azure Machine Learning.\n",
    "- Creating **Experiments** in your Workspace that capture versions of the trained model along with any desired model performance telemetry. Each time you train a model and evaluate its results, you can capture that run (model and telemetry) within an Experiment.\n",
    "- Creating **Compute** resources that can be used to scale out model training, so that while your notebook may be running in a lightweight container in Azure Notebooks, your model training can actually occur on a powerful cluster that can provide large amounts of memory, CPU or GPU. \n",
    "- Using **Automated Machine Learning (AutoML)** to automatically train multiple versions of a model using a mix of different ways to prepare the data and different algorithms and hyperparameters (algorithm settings) in search of the model that performs best according to a performance metric that you specify. \n",
    "- Packaging a Docker **Image** that contains everything your trained model needs for scoring (prediction) in order to run as a web service.\n",
    "- Deploying your Image to either Azure Kubernetes or Azure Container Instances, effectively hosting the **Web Service**.\n",
    "\n",
    "In Azure Notebooks, all of the libraries needed for Azure Machine Learning are pre-installed. To use them, you just need to import them. Run the following cell to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "from azureml.core.image import Image\n",
    "from azureml.core.model import Model\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "from azureml.core import Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and connect to an Azure Machine Learning Workspace\n",
    "\n",
    "Run the following cell to create a new Azure Machine Learning **Workspace**.\n",
    "\n",
    "**Important Note**: You will be prompted to login in the text that is output below the cell. Be sure to navigate to the URL displayed and enter the code that is provided. Once you have entered the code, return to this notebook and wait for the output to read `Workspace configuration succeeded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace configuration succeeded\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.create(\n",
    "    name = workspace_name,\n",
    "    subscription_id = subscription_id,\n",
    "    resource_group = resource_group, \n",
    "    location = workspace_region,\n",
    "    exist_ok = True)\n",
    "\n",
    "ws.write_config()\n",
    "\n",
    "print('Workspace configuration succeeded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Workspace Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in the first line of the cell below, we can re-load the config we saved previously and then display a summary of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SDK version</th>\n",
       "      <td>1.0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Workspace</th>\n",
       "      <td>quick-starts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Group</th>\n",
       "      <td>Quick-Starts-Labs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>eastus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Project Directory</th>\n",
       "      <td>./automl-regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      \n",
       "SDK version        1.0.43             \n",
       "Workspace          quick-starts       \n",
       "Resource Group     Quick-Starts-Labs  \n",
       "Location           eastus             \n",
       "Project Directory  ./automl-regression"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# Display a summary of the current environment \n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "#output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Project Directory'] = project_folder\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.DataFrame(data=output, index=['']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a new Experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remotely train multiple models using Auto ML and Azure ML Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells, you will *not* train the model against the data you just downloaded using the resources provided by Azure Notebooks. Instead, you will deploy an Azure ML Compute cluster that will download the data and use Auto ML to train multiple models, evaluate the performance and allow you to retrieve the best model that was trained. In other words, all of the training will be performed remotely with respect to this notebook. \n",
    "\n",
    "\n",
    "As you will see this is almost entirely done thru configuration, with very little code required. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the data loading script for remote compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Azure Machine Learning Compute cluster needs to know how to get the data to train against. You can package this logic in a script that will be executed by the compute when it starts executing the training.\n",
    "\n",
    "Run the following cells to locally create the **get_data.py** script that will be deployed to remote compute. You will also use this script when you want train the model locally. \n",
    "\n",
    "Observe that the get_data method returns the features (`X`) and the labels (`y`) in an object. This structure is expected later when you will configure Auto ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create project folder\n",
    "if not os.path.exists(project_folder):\n",
    "    os.makedirs(project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./automl-regression/get_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $project_folder/get_data.py\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def get_data():\n",
    "    \n",
    "    data_url = ('https://mlopswsstorage9733ce347d.blob.core.windows.net/'\n",
    "            'azureml-blobstore-4a000316-c93b-407f-b246-ed8471c34db8/'\n",
    "            'nyc-taxi-sample-data/nyc-taxi-sample-data.csv')\n",
    "    \n",
    "    df = pd.read_csv(data_url)\n",
    "    x_df = df.drop(['totalAmount'], axis=1).values\n",
    "    y_df = df['totalAmount'].values.flatten()\n",
    "    \n",
    "    return {\"X\": x_df, \"y\": y_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AML Compute Cluster\n",
    "\n",
    "Now you are ready to create the compute cluster. Run the following cell to create a new compute cluster (or retrieve the existing cluster if it already exists). The code below will create a *CPU based* cluster where each node in the cluster is of the size `STANDARD_D12_V2`, and the cluster will have at most *4* such nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-06-20T23:50:22.233000+00:00', 'errors': None, 'creationTime': '2019-06-20T23:14:03.595938+00:00', 'modifiedTime': '2019-06-20T23:14:35.228215+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D12_V2'}\n"
     ]
    }
   ],
   "source": [
    "### Create AML CPU based Compute Cluster\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D12_V2',\n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# Use the 'status' property to get a detailed status for the current AmlCompute. \n",
    "print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate an Automated ML Config\n",
    "\n",
    "Run the following cell to configure the Auto ML run. In short what you are configuring here is the training of a regressor model that will attempt to predict the value of the target (`totalAmount`) based on all the other features in the data set. The run is configured to try at most 5 iterations where no iteration can run longer that 2 minutes. \n",
    "\n",
    "Additionally, the data will be automatically pre-processed in different ways as a part of the automated model training (as indicated by the `preprocess` attribute having a value of `True`). This is a very powerful feature of Auto ML as it tries many best practices approaches for you, and saves you a lot of time and effort in the process.\n",
    "\n",
    "The goal of Auto ML in this case is to find the best models that result, as measure by the normalized root mean squared error metric (as indicated by the `primary_metric` attribute). The error is basically a measure of what the model predicts versus what was provided as the \"answer\" in the training data. In short, AutoML will try to get the error as low as possible when trying its combination of approaches.  \n",
    "\n",
    "The local path to the script you created to retrieve the data is supplied to the AutoMLConfig, ensuring the file is made available to the remote cluster. The actual execution of this training will occur on the compute cluster you created previously. \n",
    "\n",
    "In general, the AutoMLConfig is very flexible, allowing you to specify all of the following:\n",
    "- Task type (classification, regression, forecasting)\n",
    "- Number of algorithm iterations and maximum time per iteration\n",
    "- Accuracy metric to optimize\n",
    "- Algorithms to blacklist (skip)/whitelist (include)\n",
    "- Number of cross-validations\n",
    "- Compute targets\n",
    "- Training data\n",
    "\n",
    "Run the following cell to create the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_config = AutoMLConfig(task=\"regression\",\n",
    "                             iterations=5,\n",
    "                             iteration_timeout_minutes = 2, \n",
    "                             max_cores_per_iteration = 10,\n",
    "                             primary_metric=\"normalized_root_mean_squared_error\",\n",
    "                             preprocess=True,\n",
    "                             n_cross_validations = 3,\n",
    "                             debug_log = 'automl.log',\n",
    "                             verbosity = logging.DEBUG,\n",
    "                             data_script = project_folder + \"/get_data.py\",\n",
    "                             path = project_folder\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run locally\n",
    "\n",
    "You can run AutomML locally, that is it will use the resource provided by your Azure Notebook environment. \n",
    "\n",
    "Run the following cell to run the experiment locally. Note this will take **a few minutes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_45182b51-7eac-4a36-9826-f60fe141f17b\n",
      "Current status: DatasetFeaturization. Beginning to featurize the dataset.\n",
      "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the dataset.\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   StandardScalerWrapper ElasticNet               0:00:10       0.0133    0.0133\n",
      "         1   StandardScalerWrapper ElasticNet               0:00:09       0.0134    0.0133\n",
      "         2   StandardScalerWrapper ElasticNet               0:00:10       0.0138    0.0133\n",
      "         3   VotingEnsemble                                 0:00:14       0.0133    0.0133\n",
      "         4   StackEnsemble                                  0:00:09       0.0134    0.0133\n"
     ]
    }
   ],
   "source": [
    "local_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run our Experiment on AML Compute\n",
    "\n",
    "Let's increase the performance by performing the training the AML Compute cluster. This will remotely train multiple models, evaluate them and allow you review the performance characteristics of each one, as well as to pick the *best model* that was trained and download it. \n",
    "\n",
    "We will alter the configuration slightly to perform more iterations. Run the following cell to execute the experiment on the remote compute cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl-regression</td><td>AutoML_75da3347-92a5-42c5-ae2b-41615364def1</td><td>automl</td><td>Starting</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/fdbba0bc-f686-4b8b-8b29-394e0d9ae697/resourceGroups/Quick-Starts-Labs/providers/Microsoft.MachineLearningServices/workspaces/quick-starts/experiments/automl-regression/runs/AutoML_75da3347-92a5-42c5-ae2b-41615364def1\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: automl-regression,\n",
       "Id: AutoML_75da3347-92a5-42c5-ae2b-41615364def1,\n",
       "Type: automl,\n",
       "Status: Starting)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_config = AutoMLConfig(task = 'regression',\n",
    "                             iterations = 5,\n",
    "                             iteration_timeout_minutes = 2, \n",
    "                             max_cores_per_iteration = 10,\n",
    "                             preprocess= True,\n",
    "                             primary_metric='normalized_root_mean_squared_error',\n",
    "                             n_cross_validations = 3,\n",
    "                             debug_log = 'automl.log',\n",
    "                             verbosity = logging.DEBUG,\n",
    "                             data_script = project_folder + \"/get_data.py\",\n",
    "                             compute_target = compute_target,\n",
    "                             path = project_folder)\n",
    "remote_run = experiment.submit(automl_config, show_output=False)\n",
    "remote_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the above cell completes, the run is starting but will likely have a status of `Preparing` for you. To wait for the run to complete before continuing (and to view the training status updates as they happen), run the following cell. The first time you run this, it will take **about 12-15 minutes** to complete as the cluster is configured and then the AutoML job is run. Output will be streamed as the tasks progress):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   StandardScalerWrapper ElasticNet               0:00:41       0.0133    0.0133\n",
      "         1   StandardScalerWrapper ElasticNet               0:00:43       0.0134    0.0133\n",
      "         2   StandardScalerWrapper ElasticNet               0:00:38       0.0138    0.0133\n",
      "         3    VotingEnsemble                                0:00:37       0.0133    0.0133\n",
      "         4    StackEnsemble                                 0:00:38       0.0134    0.0133\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: AutoML_75da3347-92a5-42c5-ae2b-41615364def1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'AutoML_75da3347-92a5-42c5-ae2b-41615364def1',\n",
       " 'target': 'cpucluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2019-06-21T00:20:40.700006Z',\n",
       " 'endTimeUtc': '2019-06-21T00:24:07.51266Z',\n",
       " 'properties': {'num_iterations': '5',\n",
       "  'training_type': 'TrainFull',\n",
       "  'acquisition_function': 'EI',\n",
       "  'primary_metric': 'normalized_root_mean_squared_error',\n",
       "  'train_split': '0',\n",
       "  'MaxTimeSeconds': '120',\n",
       "  'acquisition_parameter': '0',\n",
       "  'num_cross_validation': '3',\n",
       "  'target': 'cpucluster',\n",
       "  'RawAMLSettingsString': \"{'name': 'automl-regression', 'path': './automl-regression', 'subscription_id': 'fdbba0bc-f686-4b8b-8b29-394e0d9ae697', 'resource_group': 'Quick-Starts-Labs', 'workspace_name': 'quick-starts', 'region': 'eastus', 'compute_target': 'cpucluster', 'spark_service': None, 'iterations': 5, 'primary_metric': 'normalized_root_mean_squared_error', 'task_type': 'regression', 'data_script': './automl-regression/get_data.py', 'validation_size': 0.0, 'n_cross_validations': 3, 'y_min': None, 'y_max': None, 'num_classes': None, 'preprocess': True, 'lag_length': 0, 'is_timeseries': False, 'max_cores_per_iteration': 10, 'max_concurrent_iterations': 1, 'iteration_timeout_minutes': 2, 'mem_in_mb': None, 'enforce_time_on_windows': False, 'experiment_timeout_minutes': None, 'experiment_exit_score': None, 'whitelist_models': None, 'blacklist_algos': ['XGBoostRegressor', 'XGBoostRegressor', 'KNeighborsClassifier', 'KNeighborsRegressor', 'SVCWrapper', 'kNN', 'kNN regressor', 'SVM'], 'auto_blacklist': True, 'blacklist_samples_reached': True, 'exclude_nan_labels': True, 'verbosity': 10, 'debug_log': 'automl.log', 'show_warnings': False, 'model_explainability': False, 'service_url': None, 'sdk_url': None, 'sdk_packages': None, 'enable_onnx_compatible_models': False, 'enable_feature_sweeping': True, 'telemetry_verbosity': 'INFO', 'send_telemetry': True, 'enable_early_stopping': False, 'early_stopping_n_iters': 10, 'metrics': None, 'enable_ensembling': True, 'enable_stack_ensembling': True, 'ensemble_iterations': 5, 'enable_tf': False, 'enable_cache': True, 'enable_subsampling': False, 'subsample_seed': None, 'cost_mode': 0, 'metric_operation': 'minimize'}\",\n",
       "  'AMLSettingsJsonString': '{\\n  \"name\": \"automl-regression\",\\n  \"path\": \"./automl-regression\",\\n  \"subscription_id\": \"fdbba0bc-f686-4b8b-8b29-394e0d9ae697\",\\n  \"resource_group\": \"Quick-Starts-Labs\",\\n  \"workspace_name\": \"quick-starts\",\\n  \"region\": \"eastus\",\\n  \"compute_target\": \"cpucluster\",\\n  \"spark_service\": null,\\n  \"iterations\": 5,\\n  \"primary_metric\": \"normalized_root_mean_squared_error\",\\n  \"task_type\": \"regression\",\\n  \"data_script\": \"./automl-regression/get_data.py\",\\n  \"validation_size\": 0.0,\\n  \"n_cross_validations\": 3,\\n  \"y_min\": null,\\n  \"y_max\": null,\\n  \"num_classes\": null,\\n  \"preprocess\": true,\\n  \"lag_length\": 0,\\n  \"is_timeseries\": false,\\n  \"max_cores_per_iteration\": 10,\\n  \"max_concurrent_iterations\": 1,\\n  \"iteration_timeout_minutes\": 2,\\n  \"mem_in_mb\": null,\\n  \"enforce_time_on_windows\": false,\\n  \"experiment_timeout_minutes\": null,\\n  \"experiment_exit_score\": null,\\n  \"whitelist_models\": null,\\n  \"blacklist_algos\": [\\n    \"XGBoostRegressor\",\\n    \"XGBoostRegressor\",\\n    \"KNeighborsClassifier\",\\n    \"KNeighborsRegressor\",\\n    \"SVCWrapper\",\\n    \"kNN\",\\n    \"kNN regressor\",\\n    \"SVM\"\\n  ],\\n  \"auto_blacklist\": true,\\n  \"blacklist_samples_reached\": true,\\n  \"exclude_nan_labels\": true,\\n  \"verbosity\": 10,\\n  \"debug_log\": \"automl.log\",\\n  \"show_warnings\": false,\\n  \"model_explainability\": false,\\n  \"service_url\": null,\\n  \"sdk_url\": null,\\n  \"sdk_packages\": null,\\n  \"enable_onnx_compatible_models\": false,\\n  \"enable_feature_sweeping\": true,\\n  \"telemetry_verbosity\": \"INFO\",\\n  \"send_telemetry\": true,\\n  \"enable_early_stopping\": false,\\n  \"early_stopping_n_iters\": 10,\\n  \"metrics\": null,\\n  \"enable_ensembling\": true,\\n  \"enable_stack_ensembling\": true,\\n  \"ensemble_iterations\": 5,\\n  \"enable_tf\": false,\\n  \"enable_cache\": true,\\n  \"enable_subsampling\": false,\\n  \"subsample_seed\": null,\\n  \"cost_mode\": 0,\\n  \"metric_operation\": \"minimize\"\\n}',\n",
       "  'DataPrepJsonString': None,\n",
       "  'EnableSubsampling': 'False',\n",
       "  'runTemplate': 'AutoML',\n",
       "  'azureml.runsource': 'automl',\n",
       "  'display_task_type': 'regression',\n",
       "  'dependencies_versions': '{\"azureml-widgets\": \"1.0.43.1\", \"azureml-train\": \"1.0.43\", \"azureml-train-restclients-hyperdrive\": \"1.0.43\", \"azureml-train-core\": \"1.0.43\", \"azureml-train-automl\": \"1.0.43.1\", \"azureml-tensorboard\": \"1.0.43\", \"azureml-telemetry\": \"1.0.43.1\", \"azureml-sdk\": \"1.0.43\", \"azureml-pipeline\": \"1.0.43\", \"azureml-pipeline-steps\": \"1.0.43\", \"azureml-pipeline-core\": \"1.0.43\", \"azureml-explain-model\": \"1.0.43\", \"azureml-dataprep\": \"1.1.4\", \"azureml-dataprep-native\": \"13.0.0\", \"azureml-core\": \"1.0.43.1\", \"azureml-contrib-services\": \"1.0.43\", \"azureml-contrib-server\": \"1.0.43\", \"azureml-contrib-opendatasets\": \"1.0.41\", \"azureml-contrib-notebook\": \"1.0.43\", \"azureml-contrib-explain-model\": \"1.0.43\", \"azureml-automl-core\": \"1.0.43\"}',\n",
       "  'ContentSnapshotId': '37611f86-7817-43f8-ac37-cfa03151adca',\n",
       "  'snapshotId': '37611f86-7817-43f8-ac37-cfa03151adca',\n",
       "  'azureml.git.repository_uri': 'https://github.com/solliancenet/azure-machine-learning-quickstarts.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/solliancenet/azure-machine-learning-quickstarts.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '3e54b61700c0c5ed704e261b8e319582fef328e9',\n",
       "  'mlflow.source.git.commit': '3e54b61700c0c5ed704e261b8e319582fef328e9',\n",
       "  'azureml.git.dirty': 'True',\n",
       "  'SetupRunId': 'AutoML_75da3347-92a5-42c5-ae2b-41615364def1_setup',\n",
       "  'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"dataset_classes\": 810, \"dataset_features\": 85, \"dataset_samples\": 11734, \"is_sparse\": true, \"subsampling\": false}'},\n",
       " 'logFiles': {}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best run and the trained model\n",
    "\n",
    "At this point you have multiple runs, each with a different trained models. How can you get the model that performed the best? Run the following cells to learn how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: automl-regression,\n",
      "Id: AutoML_75da3347-92a5-42c5-ae2b-41615364def1_0,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n",
      "RegressionPipeline(pipeline=Pipeline(memory=None,\n",
      "     steps=[('datatransformer', DataTransformer(enable_feature_sweeping=None, feature_sweeping_timeout=None,\n",
      "        is_onnx_compatible=None, logger=None, observer=None, task=None)), ('StandardScalerWrapper', <automl.client.core.common.model_wrappers.StandardScalerWrapper object at 0x7f0d44d0b128>), ('El...alse, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False))]),\n",
      "          stddev=None)\n"
     ]
    }
   ],
   "source": [
    "best_run, fitted_model = remote_run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you now have a model you could use for predicting NYC Taxi Fares. You would typically use this model in one of two ways:\n",
    "- Use the model file within other notebooks to batch score predictions.\n",
    "- Deploy the model file as a web service that applications can call. \n",
    "\n",
    "In the following, you will explore the latter option to deploy the best model as a web service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the best model \n",
    "With a run object in hand, it is trivial to download the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the best model\n",
    "best_run.download_file(\"outputs/model.pkl\",\n",
    "                       output_file_path = \"./model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Model\n",
    "\n",
    "Azure Machine Learning provides a Model Registry that acts like a version controlled repository for each of your trained models. To version a model, you use  the SDK as follows. Run the following cell to register the best model with Azure Machine Learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model nyc-taxi-automl-predictor\n",
      "Model registered: nyc-taxi-automl-predictor \n",
      "Model Description: NYC Taxi Fare Predictor \n",
      "Model Version: 3\n"
     ]
    }
   ],
   "source": [
    "# register the model for deployment\n",
    "model = Model.register(model_path = \"./model.pkl\", # this points to a local file\n",
    "                       model_name = \"nyc-taxi-automl-predictor\", # name the model is registered as\n",
    "                       tags = {'area': \"auto\", 'type': \"regression\"}, \n",
    "                       description = \"NYC Taxi Fare Predictor\", \n",
    "                       workspace = ws)\n",
    "\n",
    "print(\"Model registered: {} \\nModel Description: {} \\nModel Version: {}\".format(model.name, \n",
    "                                                                                model.description, model.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Model as a Web Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Scoring Script\n",
    "\n",
    "Azure Machine Learning SDK gives you control over the logic of the web service, so that you can define how it retrieves the model and how the model is used for scoring. This is an important bit of flexibility. For example, you often have to prepare any input data before sending it to your model for scoring. You can define this data preparation logic (as well as the model loading approach) in the scoring file. \n",
    "\n",
    "Run the following cell to create a scoring file that will be included in the Docker Image that contains your deployed web service.\n",
    "\n",
    "**Important** Please update the `model_name` variable in the script below. The model name should be the same as the `Registered model name` printed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing scoring_service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scoring_service.py\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import azureml.train.automl as AutoML\n",
    "\n",
    "columns = ['vendorID', 'passengerCount', 'tripDistance', 'hour_of_day', 'day_of_week', 'day_of_month', \n",
    "           'month_num', 'normalizeHolidayName', 'isPaidTimeOff', 'snowDepth', 'precipTime', \n",
    "           'precipDepth', 'temperature']\n",
    "\n",
    "def init():\n",
    "    try:\n",
    "        # One-time initialization of predictive model and scaler\n",
    "        from azureml.core.model import Model\n",
    "        from sklearn.externals import joblib\n",
    "        global model\n",
    "        \n",
    "        model_name = 'nyc-taxi-automl-predictor'\n",
    "        print('Looking for model path for model: ', model_name)\n",
    "        model_path = Model.get_model_path(model_name=model_name)\n",
    "        print('Looking for model in: ', model_path)\n",
    "        model = joblib.load(model_path)\n",
    "        print('Model loaded...')\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Exception during init: ', str(e))\n",
    "\n",
    "def run(input_json):     \n",
    "    try:\n",
    "        inputs = json.loads(input_json)\n",
    "        # Get the predictions...\n",
    "        prediction = model.predict(np.array(inputs).reshape(-1, len(columns))).tolist()\n",
    "        prediction = json.dumps(prediction)\n",
    "    except Exception as e:\n",
    "        prediction = str(e)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating conda dependencies file locally...\n",
      "Creating container image configuration...\n",
      "Creating image\n",
      "Running.\n",
      "NotStarted...............................................\n",
      "Succeeded\n",
      "Image creation operation finished for image nyc-taxi-automl-image:3, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# create a Conda dependencies environment file\n",
    "print(\"Creating conda dependencies file locally...\")\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "conda_packages = ['numpy', 'scikit-learn']\n",
    "pip_packages = ['azureml-sdk[automl]']\n",
    "mycondaenv = CondaDependencies.create(conda_packages=conda_packages, pip_packages=pip_packages)\n",
    "\n",
    "conda_file = 'automl_dependencies.yml'\n",
    "with open(conda_file, 'w') as f:\n",
    "    f.write(mycondaenv.serialize_to_string())\n",
    "\n",
    "runtime = 'python'\n",
    "\n",
    "# create container image configuration\n",
    "print(\"Creating container image configuration...\")\n",
    "from azureml.core.image import ContainerImage\n",
    "image_config = ContainerImage.image_configuration(execution_script = 'scoring_service.py', \n",
    "                                                  runtime = runtime, conda_file = conda_file)\n",
    "\n",
    "# create the image\n",
    "image_name = 'nyc-taxi-automl-image'\n",
    "\n",
    "from azureml.core import Image\n",
    "image = Image.create(name=image_name, models=[model], image_config=image_config, workspace=ws)\n",
    "\n",
    "# wait for image creation to finish\n",
    "image.wait_for_creation(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model to Azure Container Instance (ACI) as a Web Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating service\n",
      "Running......................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "aci_name = 'automl-aci-cluster01'\n",
    "\n",
    "aci_config = AciWebservice.deploy_configuration(\n",
    "    cpu_cores = 1, \n",
    "    memory_gb = 1, \n",
    "    tags = {'name': aci_name}, \n",
    "    description = 'NYC Taxi Fare Predictor Web Service')\n",
    "\n",
    "service_name = 'nyc-taxi-automl-service'\n",
    "\n",
    "aci_service = Webservice.deploy_from_image(deployment_config=aci_config, \n",
    "                                           image=image, \n",
    "                                           name=service_name, \n",
    "                                           workspace=ws)\n",
    "\n",
    "aci_service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the deployed web service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make direct calls on the service object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for data1\n",
      "[22.378127578013636]\n",
      "Predictions for data2\n",
      "[39.714977643580596, 22.378127578013636]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data1 = [1, 2, 5, 9, 4, 27, 5, 'Memorial Day', True, 0, 0.0, 0.0, 65]\n",
    "\n",
    "data2 = [[1, 3, 10, 15, 4, 27, 7, 'None', False, 0, 2.0, 1.0, 80], \n",
    "         [1, 2, 5, 9, 4, 27, 5, 'Memorial Day', True, 0, 0.0, 0.0, 65]]\n",
    "\n",
    "result = aci_service.run(json.dumps(data1))\n",
    "print('Predictions for data1')\n",
    "print(result)\n",
    "\n",
    "result = aci_service.run(json.dumps(data2))\n",
    "print('Predictions for data2')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make HTTP calls to test the deployed Web Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACI Service: nyc-taxi-automl-service scoring URI is: http://559acc88-453f-412b-9cbf-dfb9a7fbee2c.eastus.azurecontainer.io/score\n",
      "Predictions for data1\n",
      "\"[22.378127578013636]\"\n",
      "Predictions for data2\n",
      "\"[39.714977643580596, 22.378127578013636]\"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = aci_service.scoring_uri\n",
    "print('ACI Service: {} scoring URI is: {}'.format(service_name, url))\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "response = requests.post(url, json.dumps(data1), headers=headers)\n",
    "print('Predictions for data1')\n",
    "print(response.text)\n",
    "response = requests.post(url, json.dumps(data2), headers=headers)\n",
    "print('Predictions for data2')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
